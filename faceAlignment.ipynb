{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import dlib\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_img(path):\n",
    "    img = cv2.imread(path)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_predict(frame, left, top, right, bottom):\n",
    "    cv2.rectangle(frame, (left, top), (right, bottom), (0, 0, 255), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_eyes_nose_dlib(shape):\n",
    "    nose = shape[4][1]\n",
    "    left_eye_x = int(shape[3][1][0] + shape[2][1][0]) // 2\n",
    "    left_eye_y = int(shape[3][1][1] + shape[2][1][1]) // 2\n",
    "    right_eyes_x = int(shape[1][1][0] + shape[0][1][0]) // 2\n",
    "    right_eyes_y = int(shape[1][1][1] + shape[0][1][1]) // 2\n",
    "    return nose, (left_eye_x, left_eye_y), (right_eyes_x, right_eyes_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_eyes_nose(eyes, nose):\n",
    "    left_eye_x = int(eyes[0][0] + eyes[0][2] / 2)\n",
    "    left_eye_y = int(eyes[0][1] + eyes[0][3] / 2)\n",
    "    right_eye_x = int(eyes[1][0] + eyes[1][2] / 2)\n",
    "    right_eye_y = int(eyes[1][1] + eyes[1][3] / 2)\n",
    "    nose_x = int(nose[0][0] + nose[0][2] / 2)\n",
    "    nose_y = int(nose[0][1] + nose[0][3] / 2)\n",
    "\n",
    "    return (nose_x, nose_y), (right_eye_x, right_eye_y), (left_eye_x, left_eye_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate_point(origin, point, angle):\n",
    "    ox, oy = origin\n",
    "    px, py = point\n",
    "\n",
    "    qx = ox + np.cos(angle) * (px - ox) - np.sin(angle) * (py - oy)\n",
    "    qy = oy + np.sin(angle) * (px - ox) + np.cos(angle) * (py - oy)\n",
    "    return qx, qy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_between(point1, point2, point3, extra_point):\n",
    "    c1 = (point2[0] - point1[0]) * (extra_point[1] - point1[1]) - (point2[1] - point1[1]) * (extra_point[0] - point1[0])\n",
    "    c2 = (point3[0] - point2[0]) * (extra_point[1] - point2[1]) - (point3[1] - point2[1]) * (extra_point[0] - point2[0])\n",
    "    c3 = (point1[0] - point3[0]) * (extra_point[1] - point3[1]) - (point1[1] - point3[1]) * (extra_point[0] - point3[0])\n",
    "    if (c1 < 0 and c2 < 0 and c3 < 0) or (c1 > 0 and c2 > 0 and c3 > 0):\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance(a, b):\n",
    "    return np.sqrt((a[0] - b[0]) ** 2 + (a[1] - b[1]) ** 2)\n",
    "\n",
    "\n",
    "def cosine_formula(length_line1, length_line2, length_line3):\n",
    "    cos_a = -(length_line3 ** 2 - length_line2 ** 2 - length_line1 ** 2) / (2 * length_line2 * length_line1)\n",
    "    return cos_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_img(img):\n",
    "    while True:\n",
    "        cv2.imshow('face_alignment_app', img)\n",
    "        c = cv2.waitKey(1)\n",
    "        if c == 27:\n",
    "            break\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shape_to_normal(shape):\n",
    "    shape_normal = []\n",
    "    for i in range(0, 5):\n",
    "        shape_normal.append((i, (shape.part(i).x, shape.part(i).y)))\n",
    "    return shape_normal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate_opencv(img, nose_center, angle):\n",
    "    M = cv2.getRotationMatrix2D(nose_center, angle, 1)\n",
    "    rotated = cv2.warpAffine(img, M, (img.shape[1], img.shape[0]), flags=cv2.INTER_CUBIC)\n",
    "    return rotated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotation_detection_dlib(img):\n",
    "    detector = dlib.get_frontal_face_detector()\n",
    "    predictor = dlib.shape_predictor('./shape_predictor_68_face_landmarks.dat/shape_predictor_5_face_landmarks.dat')\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    rects = detector(gray, 0)\n",
    "    if len(rects) > 0:\n",
    "        for rect in rects:\n",
    "            x = rect.left()\n",
    "            y = rect.top()\n",
    "            w = rect.right()\n",
    "            h = rect.bottom()\n",
    "            shape = predictor(gray, rect)\n",
    "            shape = shape_to_normal(shape)\n",
    "            nose, left_eye, right_eye = get_eyes_nose_dlib(shape)\n",
    "            center_of_forehead = ((left_eye[0] + right_eye[0]) // 2, (left_eye[1] + right_eye[1]) // 2)\n",
    "            center_pred = (int((x + w) / 2), int((y + y) / 2))\n",
    "            length_line1 = distance(center_of_forehead, nose)\n",
    "            length_line2 = distance(center_pred, nose)\n",
    "            length_line3 = distance(center_pred, center_of_forehead)\n",
    "            cos_a = cosine_formula(length_line1, length_line2, length_line3)\n",
    "            angle = np.arccos(cos_a)\n",
    "            rotated_point = rotate_point(nose, center_of_forehead, angle)\n",
    "            rotated_point = (int(rotated_point[0]), int(rotated_point[1]))\n",
    "            if is_between(nose, center_of_forehead, center_pred, rotated_point):\n",
    "                angle = np.degrees(-angle)\n",
    "            else:\n",
    "                angle = np.degrees(angle)\n",
    "\n",
    "            # img = img[y:h, x:w]\n",
    "            img = rotate_opencv(img, nose, angle)\n",
    "\n",
    "            gray2 = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            faces2 = detector(gray2)\n",
    "            if len(faces2) > 0:\n",
    "                for face in faces2:\n",
    "                    x1, y1 = face.left(), face.top()\n",
    "                    x2, y2 = face.right(), face.bottom()\n",
    "                    img = img[y1:y2, x1:x2]\n",
    "                    break\n",
    "            else:\n",
    "                return img, False\n",
    "            break\n",
    "        return img, True\n",
    "    else:\n",
    "        return img, False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_img(path, img):\n",
    "    cv2.imwrite(path, img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[393], line 22\u001b[0m\n\u001b[0;32m     19\u001b[0m img1 \u001b[39m=\u001b[39m colorImages[:, :, :, i]\n\u001b[0;32m     20\u001b[0m img1 \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mcvtColor(img1, cv2\u001b[39m.\u001b[39mCOLOR_BGR2RGB)\n\u001b[1;32m---> 22\u001b[0m img1, t \u001b[39m=\u001b[39m rotation_detection_dlib(img1)\n\u001b[0;32m     23\u001b[0m img1 \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mresize(img1, (\u001b[39m256\u001b[39m, \u001b[39m256\u001b[39m), interpolation \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mINTER_AREA)\n\u001b[0;32m     24\u001b[0m \u001b[39mif\u001b[39;00m t:\n",
      "Cell \u001b[1;32mIn[391], line 3\u001b[0m, in \u001b[0;36mrotation_detection_dlib\u001b[1;34m(img)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrotation_detection_dlib\u001b[39m(img):\n\u001b[0;32m      2\u001b[0m     detector \u001b[39m=\u001b[39m dlib\u001b[39m.\u001b[39mget_frontal_face_detector()\n\u001b[1;32m----> 3\u001b[0m     predictor \u001b[39m=\u001b[39m dlib\u001b[39m.\u001b[39;49mshape_predictor(\u001b[39m'\u001b[39;49m\u001b[39m./shape_predictor_68_face_landmarks.dat/shape_predictor_5_face_landmarks.dat\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m      4\u001b[0m     gray \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mcvtColor(img, cv2\u001b[39m.\u001b[39mCOLOR_BGR2GRAY)\n\u001b[0;32m      5\u001b[0m     rects \u001b[39m=\u001b[39m detector(gray, \u001b[39m0\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dir = \"./smaller-data\"\n",
    "for filename in os.listdir(dir):\n",
    "    filepath = (os.path.join(dir, filename))\n",
    "    name = filename.split(\".\")\n",
    "    name = name[0]\n",
    "\n",
    "    videoFile = np.load(filepath)\n",
    "    colorImages = videoFile['colorImages']\n",
    "    boundingBox = videoFile['boundingBox']\n",
    "    landmarks2D = videoFile['landmarks2D']\n",
    "\n",
    "    height = colorImages.shape[0]\n",
    "    width = colorImages.shape[1]\n",
    "    size = (width, height)\n",
    "    out = cv2.VideoWriter(os.path.join('./videos2',f'{name}.mp4'), cv2.VideoWriter_fourcc(*'h264'), 25, size, isColor=False)\n",
    "    for i in range(colorImages.shape[-1]):\n",
    "        viss = []\n",
    "        img = np.ones((height, width, 3), np.uint8)\n",
    "        img1 = colorImages[:, :, :, i]\n",
    "        img1 = cv2.cvtColor(img1, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        img1, t = rotation_detection_dlib(img1)\n",
    "        img1 = cv2.resize(img1, (256, 256), interpolation = cv2.INTER_AREA)\n",
    "        if t:\n",
    "            out.write(img1)\n",
    "            cv2.imshow('video', img1)\n",
    "            c = cv2.waitKey(1)\n",
    "            if c == 27:\n",
    "                break\n",
    "    out.release()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
